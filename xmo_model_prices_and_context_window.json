{
    "claude-3-5-haiku-20241022": {
        "cache_creation_input_token_cost": 1e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 8e-08,
        "deprecation_date": "2025-10-01",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 4e-06,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 264
    },
    "claude-3-5-haiku-latest": {
        "cache_creation_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 1e-07,
        "deprecation_date": "2025-10-01",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 264
    },
    "claude-haiku-4-5-20251001": {
        "cache_creation_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost_above_1hr": 2e-06,
        "cache_read_input_token_cost": 1e-07,
        "input_cost_per_token": 1e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_computer_use": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "claude-haiku-4-5": {
        "cache_creation_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost_above_1hr": 2e-06,
        "cache_read_input_token_cost": 1e-07,
        "input_cost_per_token": 1e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_computer_use": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "claude-3-5-sonnet-20240620": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2025-06-01",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-5-sonnet-20241022": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2025-10-01",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-5-sonnet-latest": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2025-06-01",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-7-sonnet-20250219": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2026-02-01",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-7-sonnet-latest": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2025-06-01",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-haiku-20240307": {
        "cache_creation_input_token_cost": 3e-07,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-08,
        "deprecation_date": "2025-03-01",
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.25e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 264
    },
    "claude-3-opus-20240229": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 1.5e-06,
        "deprecation_date": "2025-03-01",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 395
    },
    "claude-3-opus-latest": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 1.5e-06,
        "deprecation_date": "2025-03-01",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 395
    },
    "claude-4-opus-20250514": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-4-sonnet-20250514": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost": 3e-07,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 1000000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-sonnet-4-5": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "claude-sonnet-4-5-20250929": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 200000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "claude-opus-4-1": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 3e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-opus-4-1-20250805": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 3e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-opus-4-20250514": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 3e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-sonnet-4-20250514": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "litellm_provider": "anthropic",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "gemini-1.0-pro": {
        "input_cost_per_character": 1.25e-07,
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "input_cost_per_video_per_second": 0.002,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 32760,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 3.75e-07,
        "output_cost_per_token": 1.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing#google_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-1.0-pro-001": {
        "deprecation_date": "2025-04-09",
        "input_cost_per_character": 1.25e-07,
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "input_cost_per_video_per_second": 0.002,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 32760,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 3.75e-07,
        "output_cost_per_token": 1.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-1.0-pro-002": {
        "deprecation_date": "2025-04-09",
        "input_cost_per_character": 1.25e-07,
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "input_cost_per_video_per_second": 0.002,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 32760,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 3.75e-07,
        "output_cost_per_token": 1.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-1.0-pro-vision": {
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "litellm_provider": "vertex_ai-vision-models",
        "max_images_per_prompt": 16,
        "max_input_tokens": 16384,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "max_video_length": 2,
        "max_videos_per_prompt": 1,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.0-pro-vision-001": {
        "deprecation_date": "2025-04-09",
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "litellm_provider": "vertex_ai-vision-models",
        "max_images_per_prompt": 16,
        "max_input_tokens": 16384,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "max_video_length": 2,
        "max_videos_per_prompt": 1,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.0-ultra": {
        "input_cost_per_character": 1.25e-07,
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "input_cost_per_video_per_second": 0.002,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 2048,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 3.75e-07,
        "output_cost_per_token": 1.5e-06,
        "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-1.0-ultra-001": {
        "input_cost_per_character": 1.25e-07,
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "input_cost_per_video_per_second": 0.002,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 8192,
        "max_output_tokens": 2048,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 3.75e-07,
        "output_cost_per_token": 1.5e-06,
        "source": "As of Jun, 2024. There is no available doc on vertex ai pricing gemini-1.0-ultra-001. Using gemini-1.0-pro pricing. Got max_tokens info here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-1.5-flash": {
        "input_cost_per_audio_per_second": 2e-06,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
        "input_cost_per_character": 1.875e-08,
        "input_cost_per_character_above_128k_tokens": 2.5e-07,
        "input_cost_per_image": 2e-05,
        "input_cost_per_image_above_128k_tokens": 4e-05,
        "input_cost_per_token": 7.5e-08,
        "input_cost_per_token_above_128k_tokens": 1e-06,
        "input_cost_per_video_per_second": 2e-05,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 7.5e-08,
        "output_cost_per_character_above_128k_tokens": 1.5e-07,
        "output_cost_per_token": 3e-07,
        "output_cost_per_token_above_128k_tokens": 6e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-flash-001": {
        "deprecation_date": "2025-05-24",
        "input_cost_per_audio_per_second": 2e-06,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
        "input_cost_per_character": 1.875e-08,
        "input_cost_per_character_above_128k_tokens": 2.5e-07,
        "input_cost_per_image": 2e-05,
        "input_cost_per_image_above_128k_tokens": 4e-05,
        "input_cost_per_token": 7.5e-08,
        "input_cost_per_token_above_128k_tokens": 1e-06,
        "input_cost_per_video_per_second": 2e-05,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 7.5e-08,
        "output_cost_per_character_above_128k_tokens": 1.5e-07,
        "output_cost_per_token": 3e-07,
        "output_cost_per_token_above_128k_tokens": 6e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-flash-002": {
        "deprecation_date": "2025-09-24",
        "input_cost_per_audio_per_second": 2e-06,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
        "input_cost_per_character": 1.875e-08,
        "input_cost_per_character_above_128k_tokens": 2.5e-07,
        "input_cost_per_image": 2e-05,
        "input_cost_per_image_above_128k_tokens": 4e-05,
        "input_cost_per_token": 7.5e-08,
        "input_cost_per_token_above_128k_tokens": 1e-06,
        "input_cost_per_video_per_second": 2e-05,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 7.5e-08,
        "output_cost_per_character_above_128k_tokens": 1.5e-07,
        "output_cost_per_token": 3e-07,
        "output_cost_per_token_above_128k_tokens": 6e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-flash",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-flash-exp-0827": {
        "input_cost_per_audio_per_second": 2e-06,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
        "input_cost_per_character": 1.875e-08,
        "input_cost_per_character_above_128k_tokens": 2.5e-07,
        "input_cost_per_image": 2e-05,
        "input_cost_per_image_above_128k_tokens": 4e-05,
        "input_cost_per_token": 4.688e-09,
        "input_cost_per_token_above_128k_tokens": 1e-06,
        "input_cost_per_video_per_second": 2e-05,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 1.875e-08,
        "output_cost_per_character_above_128k_tokens": 3.75e-08,
        "output_cost_per_token": 4.6875e-09,
        "output_cost_per_token_above_128k_tokens": 9.375e-09,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-flash-preview-0514": {
        "input_cost_per_audio_per_second": 2e-06,
        "input_cost_per_audio_per_second_above_128k_tokens": 4e-06,
        "input_cost_per_character": 1.875e-08,
        "input_cost_per_character_above_128k_tokens": 2.5e-07,
        "input_cost_per_image": 2e-05,
        "input_cost_per_image_above_128k_tokens": 4e-05,
        "input_cost_per_token": 7.5e-08,
        "input_cost_per_token_above_128k_tokens": 1e-06,
        "input_cost_per_video_per_second": 2e-05,
        "input_cost_per_video_per_second_above_128k_tokens": 4e-05,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 1.875e-08,
        "output_cost_per_character_above_128k_tokens": 3.75e-08,
        "output_cost_per_token": 4.6875e-09,
        "output_cost_per_token_above_128k_tokens": 9.375e-09,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-pro": {
        "input_cost_per_audio_per_second": 3.125e-05,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
        "input_cost_per_character": 3.125e-07,
        "input_cost_per_character_above_128k_tokens": 6.25e-07,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_128k_tokens": 2.5e-06,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 1.25e-06,
        "output_cost_per_character_above_128k_tokens": 2.5e-06,
        "output_cost_per_token": 5e-06,
        "output_cost_per_token_above_128k_tokens": 1e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-pro-001": {
        "deprecation_date": "2025-05-24",
        "input_cost_per_audio_per_second": 3.125e-05,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
        "input_cost_per_character": 3.125e-07,
        "input_cost_per_character_above_128k_tokens": 6.25e-07,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_128k_tokens": 2.5e-06,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 1.25e-06,
        "output_cost_per_character_above_128k_tokens": 2.5e-06,
        "output_cost_per_token": 5e-06,
        "output_cost_per_token_above_128k_tokens": 1e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-pro-002": {
        "deprecation_date": "2025-09-24",
        "input_cost_per_audio_per_second": 3.125e-05,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
        "input_cost_per_character": 3.125e-07,
        "input_cost_per_character_above_128k_tokens": 6.25e-07,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_128k_tokens": 2.5e-06,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 1.25e-06,
        "output_cost_per_character_above_128k_tokens": 2.5e-06,
        "output_cost_per_token": 5e-06,
        "output_cost_per_token_above_128k_tokens": 1e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-1.5-pro",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gemini-1.5-pro-preview-0215": {
        "input_cost_per_audio_per_second": 3.125e-05,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
        "input_cost_per_character": 3.125e-07,
        "input_cost_per_character_above_128k_tokens": 6.25e-07,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_token": 7.8125e-08,
        "input_cost_per_token_above_128k_tokens": 1.5625e-07,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 1.25e-06,
        "output_cost_per_character_above_128k_tokens": 2.5e-06,
        "output_cost_per_token": 3.125e-07,
        "output_cost_per_token_above_128k_tokens": 6.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gemini-1.5-pro-preview-0409": {
        "input_cost_per_audio_per_second": 3.125e-05,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
        "input_cost_per_character": 3.125e-07,
        "input_cost_per_character_above_128k_tokens": 6.25e-07,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_token": 7.8125e-08,
        "input_cost_per_token_above_128k_tokens": 1.5625e-07,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 1.25e-06,
        "output_cost_per_character_above_128k_tokens": 2.5e-06,
        "output_cost_per_token": 3.125e-07,
        "output_cost_per_token_above_128k_tokens": 6.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "gemini-1.5-pro-preview-0514": {
        "input_cost_per_audio_per_second": 3.125e-05,
        "input_cost_per_audio_per_second_above_128k_tokens": 6.25e-05,
        "input_cost_per_character": 3.125e-07,
        "input_cost_per_character_above_128k_tokens": 6.25e-07,
        "input_cost_per_image": 0.00032875,
        "input_cost_per_image_above_128k_tokens": 0.0006575,
        "input_cost_per_token": 7.8125e-08,
        "input_cost_per_token_above_128k_tokens": 1.5625e-07,
        "input_cost_per_video_per_second": 0.00032875,
        "input_cost_per_video_per_second_above_128k_tokens": 0.0006575,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 1.25e-06,
        "output_cost_per_character_above_128k_tokens": 2.5e-06,
        "output_cost_per_token": 3.125e-07,
        "output_cost_per_token_above_128k_tokens": 6.25e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gemini-2.0-flash": {
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "source": "https://ai.google.dev/pricing#2_0flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-flash-001": {
        "cache_read_input_token_cost": 3.75e-08,
        "deprecation_date": "2026-02-05",
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-flash-exp": {
        "cache_read_input_token_cost": 3.75e-08,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "input_cost_per_character": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_token": 1.5e-07,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "output_cost_per_token": 6e-07,
        "output_cost_per_token_above_128k_tokens": 0,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-flash-lite": {
        "cache_read_input_token_cost": 1.875e-08,
        "input_cost_per_audio_token": 7.5e-08,
        "input_cost_per_token": 7.5e-08,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 50,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-flash-lite-001": {
        "cache_read_input_token_cost": 1.875e-08,
        "deprecation_date": "2026-02-25",
        "input_cost_per_audio_token": 7.5e-08,
        "input_cost_per_token": 7.5e-08,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 50,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 3e-07,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-flash-live-preview-04-09": {
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 3e-06,
        "input_cost_per_image": 3e-06,
        "input_cost_per_token": 5e-07,
        "input_cost_per_video_per_second": 3e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_audio_token": 1.2e-05,
        "output_cost_per_token": 2e-06,
        "rpm": 10,
        "source": "https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini#gemini-2-0-flash-live-preview-04-09",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 250000
    },
    "gemini-2.0-flash-preview-image-generation": {
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "source": "https://ai.google.dev/pricing#2_0flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-flash-thinking-exp": {
        "cache_read_input_token_cost": 0.0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "input_cost_per_character": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-flash-thinking-exp-01-21": {
        "cache_read_input_token_cost": 0.0,
        "input_cost_per_audio_per_second": 0,
        "input_cost_per_audio_per_second_above_128k_tokens": 0,
        "input_cost_per_character": 0,
        "input_cost_per_character_above_128k_tokens": 0,
        "input_cost_per_image": 0,
        "input_cost_per_image_above_128k_tokens": 0,
        "input_cost_per_token": 0,
        "input_cost_per_token_above_128k_tokens": 0,
        "input_cost_per_video_per_second": 0,
        "input_cost_per_video_per_second_above_128k_tokens": 0,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65536,
        "max_pdf_size_mb": 30,
        "max_tokens": 65536,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_character_above_128k_tokens": 0,
        "output_cost_per_token": 0,
        "output_cost_per_token_above_128k_tokens": 0,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.0-flash",
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": false,
        "supports_function_calling": false,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": false,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.0-pro-exp-02-05": {
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 2097152,
        "max_output_tokens": 8192,
        "max_pdf_size_mb": 30,
        "max_tokens": 8192,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_video_input": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-flash": {
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-flash-image": {
        "cache_read_input_token_cost": 3e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 32768,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "max_pdf_size_mb": 30,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "image_generation",
        "output_cost_per_image": 0.039,
        "output_cost_per_reasoning_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "rpm": 100000,
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-flash-image",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 8000000
    },
    "gemini-2.5-flash-image-preview": {
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "image_generation",
        "output_cost_per_image": 0.039,
        "output_cost_per_reasoning_token": 3e-05,
        "output_cost_per_token": 3e-05,
        "rpm": 100000,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tpm": 8000000
    },
    "gemini-2.5-flash-lite": {
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 5e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-flash-lite-preview-09-2025": {
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 3e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-flash-preview-09-2025": {
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "source": "https://developers.googleblog.com/en/continuing-to-bring-you-our-latest-models-with-an-improved-gemini-2-5-flash-and-flash-lite-release/",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-flash-lite-preview-06-17": {
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_audio_token": 5e-07,
        "input_cost_per_token": 1e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 4e-07,
        "output_cost_per_token": 4e-07,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-flash-preview-04-17": {
        "cache_read_input_token_cost": 3.75e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 3.5e-06,
        "output_cost_per_token": 6e-07,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-flash-preview-05-20": {
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_audio_token": 1e-06,
        "input_cost_per_token": 3e-07,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_reasoning_token": 2.5e-06,
        "output_cost_per_token": 2.5e-06,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_url_context": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-pro": {
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_video_input": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-pro-exp-03-25": {
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_input": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_video_input": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-pro-preview-03-25": {
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_audio_token": 1.25e-06,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-pro-preview-05-06": {
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_audio_token": 1.25e-06,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supported_regions": [
            "global"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-pro-preview-06-05": {
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_audio_token": 1.25e-06,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "source": "https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-preview",
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio",
            "video"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-2.5-pro-preview-tts": {
        "cache_read_input_token_cost": 3.125e-07,
        "input_cost_per_audio_token": 7e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "litellm_provider": "vertex_ai-language-models",
        "max_audio_length_hours": 8.4,
        "max_audio_per_prompt": 1,
        "max_images_per_prompt": 3000,
        "max_input_tokens": 1048576,
        "max_output_tokens": 65535,
        "max_pdf_size_mb": 30,
        "max_tokens": 65535,
        "max_video_length": 1,
        "max_videos_per_prompt": 10,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
        "source": "https://ai.google.dev/gemini-api/docs/pricing#gemini-2.5-pro-preview",
        "supported_modalities": [
            "text"
        ],
        "supported_output_modalities": [
            "audio"
        ],
        "supports_audio_output": false,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gemini-embedding-001": {
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "vertex_ai-embedding-models",
        "max_input_tokens": 2048,
        "max_tokens": 2048,
        "mode": "embedding",
        "output_cost_per_token": 0,
        "output_vector_size": 3072,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models"
    },
    "gemini-flash-experimental": {
        "input_cost_per_character": 0,
        "input_cost_per_token": 0,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_token": 0,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental",
        "supports_function_calling": false,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-pro": {
        "input_cost_per_character": 1.25e-07,
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "input_cost_per_video_per_second": 0.002,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 32760,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 3.75e-07,
        "output_cost_per_token": 1.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/pricing",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-pro-experimental": {
        "input_cost_per_character": 0,
        "input_cost_per_token": 0,
        "litellm_provider": "vertex_ai-language-models",
        "max_input_tokens": 1000000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_character": 0,
        "output_cost_per_token": 0,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/gemini-experimental",
        "supports_function_calling": false,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true
    },
    "gemini-pro-vision": {
        "input_cost_per_image": 0.0025,
        "input_cost_per_token": 5e-07,
        "litellm_provider": "vertex_ai-vision-models",
        "max_images_per_prompt": 16,
        "max_input_tokens": 16384,
        "max_output_tokens": 2048,
        "max_tokens": 2048,
        "max_video_length": 2,
        "max_videos_per_prompt": 1,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "source": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_models",
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "glm-4.6": {
        "litellm_provider": "zhipuai",
        "max_input_tokens": 200000,
        "max_output_tokens": 200000,
        "max_tokens": 200000,
        "mode": "chat",
        "source": "https://open.bigmodel.cn/pricing",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "tiered_pricing": [
            {
                "cache_read_input_token_cost": 4e-07,
                "input_cost_per_token": 2e-06,
                "output_cost_per_token": 8e-06,
                "range": [
                    0,
                    32000.0
                ],
                "output_range": [
                    0,
                    200.0
                ]
            },
            {
                "cache_read_input_token_cost": 6e-07,
                "input_cost_per_token": 3e-06,
                "output_cost_per_token": 1.4e-05,
                "range": [
                    0,
                    32000.0
                ],
                "output_range": [
                    200.0,
                    null
                ]
            },
            {
                "cache_read_input_token_cost": 8e-07,
                "input_cost_per_token": 4e-06,
                "output_cost_per_token": 1.6e-05,
                "range": [
                    32000.0,
                    200000.0
                ]
            }
        ]
    },
    "gpt-4": {
        "input_cost_per_token": 3e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-0125-preview": {
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-0314": {
        "input_cost_per_token": 3e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-0613": {
        "deprecation_date": "2025-06-06",
        "input_cost_per_token": 3e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-1106-preview": {
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-1106-vision-preview": {
        "deprecation_date": "2024-12-06",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4-32k": {
        "input_cost_per_token": 6e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.00012,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-32k-0314": {
        "input_cost_per_token": 6e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.00012,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-32k-0613": {
        "input_cost_per_token": 6e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.00012,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-turbo": {
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4-turbo-2024-04-09": {
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4-turbo-preview": {
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-vision-preview": {
        "deprecation_date": "2024-12-06",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.1": {
        "cache_read_input_token_cost": 5e-07,
        "cache_read_input_token_cost_priority": 8.75e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "input_cost_per_token_priority": 3.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "output_cost_per_token_batches": 4e-06,
        "output_cost_per_token_priority": 1.4e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.1-2025-04-14": {
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "output_cost_per_token_batches": 4e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.1-mini": {
        "cache_read_input_token_cost": 1e-07,
        "cache_read_input_token_cost_priority": 1.75e-07,
        "input_cost_per_token": 4e-07,
        "input_cost_per_token_batches": 2e-07,
        "input_cost_per_token_priority": 7e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1.6e-06,
        "output_cost_per_token_batches": 8e-07,
        "output_cost_per_token_priority": 2.8e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.1-mini-2025-04-14": {
        "cache_read_input_token_cost": 1e-07,
        "input_cost_per_token": 4e-07,
        "input_cost_per_token_batches": 2e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1.6e-06,
        "output_cost_per_token_batches": 8e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.1-nano": {
        "cache_read_input_token_cost": 2.5e-08,
        "cache_read_input_token_cost_priority": 5e-08,
        "input_cost_per_token": 1e-07,
        "input_cost_per_token_batches": 5e-08,
        "input_cost_per_token_priority": 2e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "output_cost_per_token_batches": 2e-07,
        "output_cost_per_token_priority": 8e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.1-nano-2025-04-14": {
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "input_cost_per_token_batches": 5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "output_cost_per_token_batches": 2e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.5-preview": {
        "cache_read_input_token_cost": 3.75e-05,
        "input_cost_per_token": 7.5e-05,
        "input_cost_per_token_batches": 3.75e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 0.00015,
        "output_cost_per_token_batches": 7.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.5-preview-2025-02-27": {
        "cache_read_input_token_cost": 3.75e-05,
        "deprecation_date": "2025-07-14",
        "input_cost_per_token": 7.5e-05,
        "input_cost_per_token_batches": 3.75e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 0.00015,
        "output_cost_per_token_batches": 7.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o": {
        "cache_read_input_token_cost": 1.25e-06,
        "cache_read_input_token_cost_priority": 2.125e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "input_cost_per_token_priority": 4.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "output_cost_per_token_priority": 1.7e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-2024-05-13": {
        "input_cost_per_token": 5e-06,
        "input_cost_per_token_batches": 2.5e-06,
        "input_cost_per_token_priority": 8.75e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_batches": 7.5e-06,
        "output_cost_per_token_priority": 2.625e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-2024-08-06": {
        "cache_read_input_token_cost": 1.25e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-2024-11-20": {
        "cache_read_input_token_cost": 1.25e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-audio-preview": {
        "input_cost_per_audio_token": 0.0001,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 0.0002,
        "output_cost_per_token": 1e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-audio-preview-2024-10-01": {
        "input_cost_per_audio_token": 0.0001,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 0.0002,
        "output_cost_per_token": 1e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-audio-preview-2024-12-17": {
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 1e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-audio-preview-2025-06-03": {
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 1e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini": {
        "cache_read_input_token_cost": 7.5e-08,
        "cache_read_input_token_cost_priority": 1.25e-07,
        "input_cost_per_token": 1.5e-07,
        "input_cost_per_token_batches": 7.5e-08,
        "input_cost_per_token_priority": 2.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "output_cost_per_token_batches": 3e-07,
        "output_cost_per_token_priority": 1e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-mini-2024-07-18": {
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_token": 1.5e-07,
        "input_cost_per_token_batches": 7.5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "output_cost_per_token_batches": 3e-07,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.03,
            "search_context_size_low": 0.025,
            "search_context_size_medium": 0.0275
        },
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-mini-audio-preview": {
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 6e-07,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-audio-preview-2024-12-17": {
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 6e-07,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-realtime-preview": {
        "cache_creation_input_audio_token_cost": 3e-07,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 2.4e-06,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-realtime-preview-2024-12-17": {
        "cache_creation_input_audio_token_cost": 3e-07,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 2.4e-06,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-search-preview": {
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_token": 1.5e-07,
        "input_cost_per_token_batches": 7.5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "output_cost_per_token_batches": 3e-07,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.03,
            "search_context_size_low": 0.025,
            "search_context_size_medium": 0.0275
        },
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gpt-4o-mini-search-preview-2025-03-11": {
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_token": 1.5e-07,
        "input_cost_per_token_batches": 7.5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "output_cost_per_token_batches": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-mini-transcribe": {
        "input_cost_per_audio_token": 3e-06,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16000,
        "max_output_tokens": 2000,
        "mode": "audio_transcription",
        "output_cost_per_token": 5e-06,
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "gpt-4o-mini-tts": {
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "mode": "audio_speech",
        "output_cost_per_audio_token": 1.2e-05,
        "output_cost_per_second": 0.00025,
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/audio/speech"
        ],
        "supported_modalities": [
            "text",
            "audio"
        ],
        "supported_output_modalities": [
            "audio"
        ]
    },
    "gpt-4o-realtime-preview": {
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-realtime-preview-2024-10-01": {
        "cache_creation_input_audio_token_cost": 2e-05,
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_audio_token": 0.0001,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 0.0002,
        "output_cost_per_token": 2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-realtime-preview-2024-12-17": {
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-realtime-preview-2025-06-03": {
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-search-preview": {
        "cache_read_input_token_cost": 1.25e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.05,
            "search_context_size_low": 0.03,
            "search_context_size_medium": 0.035
        },
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gpt-4o-search-preview-2025-03-11": {
        "cache_read_input_token_cost": 1.25e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-transcribe": {
        "input_cost_per_audio_token": 6e-06,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16000,
        "max_output_tokens": 2000,
        "mode": "audio_transcription",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/audio/transcriptions"
        ]
    },
    "gpt-5": {
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_flex": 6.25e-08,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_flex": 6.25e-07,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_flex": 5e-06,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5-pro": {
        "input_cost_per_token": 1.5e-05,
        "input_cost_per_token_batches": 7.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 400000,
        "max_output_tokens": 272000,
        "max_tokens": 272000,
        "mode": "responses",
        "output_cost_per_token": 1.2e-04,
        "output_cost_per_token_batches": 6e-05,
        "supported_endpoints": [
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": false,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gpt-5-pro-2025-10-06": {
        "input_cost_per_token": 1.5e-05,
        "input_cost_per_token_batches": 7.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 400000,
        "max_output_tokens": 272000,
        "max_tokens": 272000,
        "mode": "responses",
        "output_cost_per_token": 1.2e-04,
        "output_cost_per_token_batches": 6e-05,
        "supported_endpoints": [
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": false,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gpt-5-2025-08-07": {
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_flex": 6.25e-08,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_flex": 6.25e-07,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_flex": 5e-06,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_service_tier": true,
        "supports_vision": true
    },
    "gpt-5-chat": {
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": false,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "gpt-5-chat-latest": {
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": false,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "gpt-5-codex": {
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5-mini": {
        "cache_read_input_token_cost": 2.5e-08,
        "cache_read_input_token_cost_flex": 1.25e-08,
        "cache_read_input_token_cost_priority": 4.5e-08,
        "input_cost_per_token": 2.5e-07,
        "input_cost_per_token_flex": 1.25e-07,
        "input_cost_per_token_priority": 4.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "output_cost_per_token_flex": 1e-06,
        "output_cost_per_token_priority": 3.6e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5-mini-2025-08-07": {
        "cache_read_input_token_cost": 2.5e-08,
        "cache_read_input_token_cost_flex": 1.25e-08,
        "cache_read_input_token_cost_priority": 4.5e-08,
        "input_cost_per_token": 2.5e-07,
        "input_cost_per_token_flex": 1.25e-07,
        "input_cost_per_token_priority": 4.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "output_cost_per_token_flex": 1e-06,
        "output_cost_per_token_priority": 3.6e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5-nano": {
        "cache_read_input_token_cost": 5e-09,
        "cache_read_input_token_cost_flex": 2.5e-09,
        "input_cost_per_token": 5e-08,
        "input_cost_per_token_flex": 2.5e-08,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "output_cost_per_token_flex": 2e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5-nano-2025-08-07": {
        "cache_read_input_token_cost": 5e-09,
        "cache_read_input_token_cost_flex": 2.5e-09,
        "input_cost_per_token": 5e-08,
        "input_cost_per_token_flex": 2.5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "output_cost_per_token_flex": 2e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-image-1": {
        "input_cost_per_pixel": 4.0054321e-08,
        "litellm_provider": "openai",
        "mode": "image_generation",
        "output_cost_per_pixel": 0.0,
        "supported_endpoints": [
            "/v1/images/generations"
        ]
    },
    "gpt-image-1-mini": {
        "cache_read_input_image_token_cost": 2.5e-07,
        "cache_read_input_token_cost": 2e-07,
        "input_cost_per_image_token": 2.5e-06,
        "input_cost_per_token": 2e-06,
        "litellm_provider": "openai",
        "mode": "chat",
        "output_cost_per_image_token": 8e-06,
        "supported_endpoints": [
            "/v1/images/generations",
            "/v1/images/edits"
        ]
    },
    "gpt-realtime": {
        "cache_creation_input_audio_token_cost": 4e-07,
        "cache_read_input_token_cost": 4e-07,
        "input_cost_per_audio_token": 3.2e-05,
        "input_cost_per_image": 5e-06,
        "input_cost_per_token": 4e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 32000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 6.4e-05,
        "output_cost_per_token": 1.6e-05,
        "supported_endpoints": [
            "/v1/realtime"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-realtime-mini": {
        "cache_creation_input_audio_token_cost": 3e-07,
        "cache_read_input_audio_token_cost": 3e-07,
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 2.4e-06,
        "supported_endpoints": [
            "/v1/realtime"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-realtime-2025-08-28": {
        "cache_creation_input_audio_token_cost": 4e-07,
        "cache_read_input_token_cost": 4e-07,
        "input_cost_per_audio_token": 3.2e-05,
        "input_cost_per_image": 5e-06,
        "input_cost_per_token": 4e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 32000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 6.4e-05,
        "output_cost_per_token": 1.6e-05,
        "supported_endpoints": [
            "/v1/realtime"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "kimi-k2-0905-preview": {
        "cache_read_input_token_cost": 1.5e-07,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "moonshot",
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 2.5e-06,
        "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
    "kimi-k2-turbo-preview": {
        "cache_read_input_token_cost": 6e-07,
        "input_cost_per_token": 2.4e-06,
        "litellm_provider": "moonshot",
        "max_input_tokens": 262144,
        "max_output_tokens": 262144,
        "max_tokens": 262144,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "source": "https://platform.moonshot.ai/docs/pricing/chat#generation-model-kimi-k2",
        "supports_function_calling": true,
        "supports_tool_choice": true,
        "supports_web_search": true
    },
        "qwen3-max": {
        "litellm_provider": "dashscope",
        "max_input_tokens": 258048,
        "max_output_tokens": 65536,
        "max_tokens": 262144,
        "mode": "chat",
        "source": "https://help.aliyun.com/zh/model-studio/getting-started/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "tiered_pricing": [
            {
                "input_cost_per_token": 6e-06,
                "output_cost_per_token": 2.4e-05,
                "range": [
                    0,
                    32000.0
                ]
            },
            {
                "input_cost_per_token": 1e-05,
                "output_cost_per_token": 4e-05,
                "range": [
                    32000.0,
                    128000.0
                ]
            },
            {
                "input_cost_per_token": 1.5e-05,
                "output_cost_per_token": 6e-05,
                "range": [
                    128000.0,
                    252000.0
                ]
            }
        ]
    },
    "qwen3-max-2025-09-23": {
        "litellm_provider": "dashscope",
        "max_input_tokens": 258048,
        "max_output_tokens": 65536,
        "max_tokens": 262144,
        "mode": "chat",
        "source": "https://help.aliyun.com/zh/model-studio/getting-started/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "tiered_pricing": [
            {
                "input_cost_per_token": 6e-06,
                "output_cost_per_token": 2.4e-05,
                "range": [
                    0,
                    32000.0
                ]
            },
            {
                "input_cost_per_token": 1e-05,
                "output_cost_per_token": 4e-05,
                "range": [
                    32000.0,
                    128000.0
                ]
            },
            {
                "input_cost_per_token": 1.5e-05,
                "output_cost_per_token": 6e-05,
                "range": [
                    128000.0,
                    252000.0
                ]
            }
        ]
    },
    "qwen3-max-preview": {
        "litellm_provider": "dashscope",
        "max_input_tokens": 258048,
        "max_output_tokens": 65536,
        "max_tokens": 262144,
        "mode": "chat",
        "source": "https://help.aliyun.com/zh/model-studio/getting-started/models",
        "supports_function_calling": true,
        "supports_reasoning": true,
        "supports_tool_choice": true,
        "tiered_pricing": [
            {
                "input_cost_per_token": 6e-06,
                "output_cost_per_token": 2.4e-05,
                "range": [
                    0,
                    32000.0
                ]
            },
            {
                "input_cost_per_token": 1e-05,
                "output_cost_per_token": 4e-05,
                "range": [
                    32000.0,
                    128000.0
                ]
            },
            {
                "input_cost_per_token": 1.5e-05,
                "output_cost_per_token": 6e-05,
                "range": [
                    128000.0,
                    252000.0
                ]
            }
        ]
    }
}